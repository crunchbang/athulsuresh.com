#+hugo_base_dir: ../

* Hello World :@life:
:PROPERTIES:
:EXPORT_DATE: 2020-05-03
:EXPORT_FILE_NAME: 01-hello-world
:END:
Hello!

Is there anybody out there?

Nod if you can hear me

This blog is my poor attempt to document all the werid bugs I have encountered in production and the valuable lessons they've taught me.

It took me 5 attempts just to get this page up and running. Hmm. There must be story here that I can stretch to a blog post.
* Bug Story: It's not you, it's the environment :@tech:
:PROPERTIES:
:EXPORT_FILE_NAME: 02-bug-ttl
:EXPORT_DATE: 2020-05-03
:END:

It all started with a deployment to the production cluster.

It always does. The worst things happen when you deploy to prod.

*** Background
In our production cluster, we use Aerospike as the primary data store, with data being synced to MySQL for long term storage. For the uninitiated, Aerospike is a high speed, distributed key-value NoSQL database which provides a lot of cool features. Check it [[https://www.aerospike.com/][out]] if you haven't already. In our cluster, all transactional data gets written to or read from AS, with MySQL being used only as a fallback option. We have a dedicated service that sync data from AS to MySQL and keeps things in check. The speed of access and the ability to scale by adding new nodes helps us keep the pressure off our central MySQL datastore.

I was working on a project that migrated one of our legacy use cases from MySQL to Aerospike. Like all legacy software, this one had a bunch of implicit assumptions about the data store baked into the code, the primary one being persistence. A note about Aersopike - typically data are stored in Aerospike records with a *TTL* (Time To Live). The data gets evicted automatically by the Aerospike engine and this reduces a lot of manual garbage collection from our side. Sadly, this would not be a preferable trait for my use case, as the data was expected to be persisted for weeks or even months, while our typical *TTL* was about a week. Fortunately for me, AS provided a way to persist data indefinitely using ~-1~ as the *TTL*. Yes! Problem solved. This was the least of my worries as I had to abuse Aersopike in ways that would make its creators cry. That is a story for another post.

I made the required changes, tested out the code, and things seemed to have improved drastically. After a round of code review, I was ready for deployment. The deployment progressed as usual. The use-case was served by a set of APIs, so I was monitoring the cluster for 5xx or any usual errors. The whole thing was done in about 10 mins and all the signals from the cluster were green. No 5xx. No uncaught errors. I patted myself on the back for a smooth deployment (those seem to be a rarity in my life these days).

*** A series of unfortunate events

Remember all those movie characters who celebrated early and later gets killed? A similar, but much less gruesome fate awaited me.

It started with the load balancer throwing 5xx. On further investigation, I found that the backend instance was not responding to certain requests. Digging deeper and grepping through the logs, I saw that request processing for one of the APIs for a completely different use-case was causing it. From the logs, it looked like the request was processed midway and then things abruptly stopped.

Weird indeed.

I did not have a lot of time as this was hitting production traffic (Blue-Green deployments, you say? We've never heard of it). So I quickly reverted the code to the previous stable version and dug deeper.

Delving into the code, I saw that processing stopped abruptly at a point where we were inserting some data into Aersopike with a *TTL* of ~-1~. A little bit of context here - our internal wrapper over the AS client library had put some checks in place to prevent people from persisting data forever (*TTL* = ~-1~). Whenever someone passed in ~-1~, it'd quietly change that into 7 days and pass it along to the AS library. This was abused in several places in our code base where ~-1~ would be passed in since they expected the lib to put in some default value. This would not do for my case and I'd changed the wrapper to pass ~-1~ as is to the underlying layers. The offending piece of code was one where ~-1~ was being passed. So I narrowed down my search and tried calling our client wrapper with ~-1~ on the instance. I was greeted with a Segmentation Fault from the underlying library. Ah ha! Problem solved!

Well, not exactly. Why did I not get this bug while testing? Our deployments process is a little weird. We have a copy of each dependency stashed away in an S3 bucket which we pull during the deployment. I had used the same version of the lib during testing and the bug did not manifest for me. I dug even deeper (God, when will this stop?!!).

On checking the library version in one of the instances, I found that it had an older version of the lib installed. Suspecting something wrong with the deployment, I pulled up the deployment scripts, expecting to see something amiss. The Aerospike client deployment part was pretty straight forward:

#+begin_src bash
# script set up

cd /usr/src
wget https://s3.xyz.com/abc/aerospike_client.zip -O aerospike_client.zip
unzip aerospike_client.zip
cd <unzipped dir>

# make and install
#+end_src

Things looks right. Nothing out of place. I ran just the client deployment script and checked again. It was still showing the older version of the library!

Super werid.

Somehow it dawned on me to check the man pages for unzip. Usually when you uzip a file and if the resulting directory already exists then unzip will prompt you regarding the next course of action. But when the same script is triggered through an ansible role, it'll silently do nothing and move on with the rest of the flow. Therein lies the problem!

The base AMI we were using already had the unzipped folder baked in with the old version of the library. Whenever the deployment script ran, we downloaded the library code, and tried to unzip it. With no-one to tell it what to do, unzip silently did nothing. Not a single thing. Looking closer, I found that this had been the case since 2016. For 4 years, we had happily deployed code with not a single soul knowing that things were not being deployed as expected.

The fix was a simple addition of the ~-o~ flag to the unzip command so that it could pummel through anyone and anything that stood in its way.

This seemingly innocuous bug took me from high level application code, to Aerospike client library code, and then, down to our deployment script. All of this because someone did not explicitly instruct unzip to replace while extracting its contents.

All for want of a ~-o~ flag.

*** Lessons Learned
- Don't deploy on a Friday. Have some heart and think about your on-call engineers.
- Things can blow up in your face. Be ready to log it when it happens. I had to manually test the client wrapper to find that it was a SEGFAULT.
- Don't always assume the fault is in your code. Never blindly trust client libraries to do the right thing. We're all human after all.
- Don't put conflicting defaults in client wrapper code.
- Don't be an idiot like me and try to change those defaults. Once out in the wild, every perceivable behavior of a lib will be (ab)used by programmers.
- Read the Frickin' Manual & Be EXPLICIT with your command. Bash has enough red tape around it as is. Make sure that your favorite tools behave the way you
  expect when you plug it into a script. Always err on the side of verbosity and add flags to ensure the expected behavior.
- Always be ready to dig further. You will most definitely end up learning a lot with a good story to boot.

Ping me your thoughts and comments.
* Wrong Tool For The Job: Concurrent Queues with Aerospike
:PROPERTIES:
:EXPORT_FILE_NAME: 03-wrong-tool
:EXPORT_DATE: 2020-05-16
:END:
** If all you have is a hammer...
Organizational choices and system architecture sometimes forces you to use sub-optimal tools for a problem. In fact, this is part of the challenge that work throws at you - having to retrofit or abuse tools to get the job done.

If you always had the right set of tools, what fun would life be? This is one such problem.

** The Problem

We had an antiquated use case which allowed customers to create a deferred list of jobs. These jobs would then be processed based on API requests from the customer's end. These lists would usually range from about 100 - 100000 jobs. We also provided a provision whereby the customer could trigger multiple requests in parallel to enable concurrent processing of these jobs. The original design dumped these jobs into MySQL, given that these jobs had to be persisted indefinitely until a trigger was detected.

Stepping back from the nitty-gritty details, you can see that this is in essence a concurrent queue modeled on MySQL. The original implementation was not optimized for our traffic and it suffered from race conditions. We were handling a level of traffic which had caused DB outages in the past, so we did not want to lean on MySQL too much.

Given the scale of the traffic, the criticality of the DB to serve our operations, and the sensitivity of this use-case to latency, it was decided that Aersopike would be used as the primary data store instead of MySQL. As I'd mentioned in my previous post, we use Aerospike A LOT - mostly because it's blazing fast and scalable, but also because it's free. We have a data sync mechanism that syncs data from Aerospike to MySQL once the records have been processed.

Data stores were never meant to be used as a job queue and it required some effort to get Aerospike to do the same.

** The FCFS Way
:PROPERTIES:
:ID:       31e60ff5-37a0-454b-b913-95473a9f5d9d
:END:

The straightforward way is to implement a First Come First Server (FCFS) system whereby each incoming request would find the first unprocessed job, reserve it, and then proceed with its processing.

In a concurrent environment, whenever there's a two step process to reserve a job, there's bound to be race conditions - two requests could come up on the same job, reserve them, and then proceed with the processing of the same job. Even if we were to look past the race condition, this approach would take *O(N)* time to service to request in the worst case, with *N* being the total number of jobs in the queue. Ideally, we'd prefer to have a single operation to reserve the job.

[[/image-1.png]]


** The ID Store

To prevent each request traversing the entire length of the job queue we set up a job ~ID Store~ which contains the list of all unprocessed jobs.

This was implemented in Aerospike using the list aggregate type, which we used to store the list of unprocessed job IDs. List pop operation (provided by Aerospike) allowed us to get a Job ID while still ensuring isolation between requests. In addition, the jobs were indexed based on job IDs for faster access.

Thus each request would first pop off from the ~ID store~ and select the corresponding job from the jobs set. This has the dual benefit of avoiding race conditions by leaning on the storage engine to ensure isolation, and decreasing the worst case job assignment complexity to *O(1)*.

[[/image-2.png]]

The only downside here is the Aerospike record limit. Each record in Aerospike is like a row in a SQL DB and Aerospike has a (configurable) limit on the size of each record. Unlucky for me, this limit was set at ~128KB~ in our system. If we assume each job ID to be ~8B~, then we can accommodate only 16000 IDs per record.

Can we do better?

** The Token Store Optimization

We had to store the list of job IDs because they're usually non-contiguous numeric identifiers. We can forego this list, if we assign sequential token IDs to each job. This indexed field provides an alternative way to refer to jobs within a set. The ~ID Store~, which we'll now call the ~Token Store~, will contain the token ID of the next job to be processed. You can think of it as a pointer to the job queue. This will help us tide over the record size limitations.

To reserve a job, a request would get the current token ID in the ~Token Store~, fetch the corresponding record from the job set and then increment the token value so that it points to the next unprocessed job.

While this looks efficient, it brings back the inevitable race condition - two jobs could read the same value and reserve the same job. What we need is an atomic operation to deal with the token ID.

Aersopike provides the facility to define *User Defined Functions(UDF)* in Lua which allows us to define new functions that are guaranteed to be atomic by the storage engine. So, we defined a UDF to implement the read-increment-write operation which would read the token value, increment it, write the incremented value, and return the old value. Thus, each incoming request would invoke the read-increment-write UDF on ~Token Store~ to get the token ID, and would use this ID to get the corresponding job.

We've thus managed to stick to *O(1)* for job assignment while cutting down the space requirement of the list.

[[/image-3.png]]

** Drawbacks

The primary downside is that we have no way to ensure fault tolerance. If a request, which reserved a job, dies then we have no way to put that job back into the pool of reserved jobs. Thus the optimization might not be useful in the general context, but was acceptable for our specific use-case.

** Alternatives

*** Using a SQL DB

Aerospike is a NoSQL datastore and thus do not provide the rich set of operations made available by SQL. As outlined in this [[https://dba.stackexchange.com/questions/98311/best-way-to-implement-concurrent-table-based-queue?newreg=fdb55e93bbf64b1ca64778fd25518934][answer on Database Administrator]], SQL databases like MySQL enables us to use a combination of ~Transactions~ and ~SELECT FOR UPDATE~ to achieve the same result, albeit with a slightly higher performance penalty.

We couldn't use it for our use-case as our MySQL DB was /far too/ precious to be put under heavy load from such a bursty workflow.

*** Using a Message Queue

A simple persistent message queue like [[https://beanstalkd.github.io/][Beanstalkd]] would've been a perfect fit for this problem. Message Queues have the concept of tubes, which provides a high level way to group messages, which could be used for organizing jobs from different customers into different tubes. They also provide facilities like delays, whereby a job is put back into the queue if the reserved consumer has not responded withing a stipulated time frame, which would take care of the fault tolerance aspect.

We couldn't use this solution because our services had some design decisions baked in, which made integrating a message queue into the flow a non-trivial exercise.

** Lessons Learned

- Your problem does not exist in a vacuum. Your possible solutions would be constrained by the environment you operate in.
- Technical decisions, especially in the context of services, have long term repercussions that would influence the enhancements and modifications that could be carried out on it.
- Be realistic about the effort involved in implementing the perfect solution, in view of the time constraints - job Queues would've been perfect, but an optimized Aerospike setup was the next best option.
- Know when to stop. Optimization are an unending rabbit hole.
- Prefer clarity over cleverness /wherever possible/.

This blog post is my explanation for future maintainers of my code as to how things reached the state they are in now. I did what had to be done. :P

Ping me your thoughts and comments.

Check out [[https://www.aerospike.com/][Aerospike]] and [[https://beanstalkd.github.io/][Beanstalkd]], if you haven't already!

All diagrams were created using [[https://sketchviz.com/new][Sketchviz]].
* Notes from 'Linux Kernel Development'
:PROPERTIES:
:EXPORT_FILE_NAME: 04-notes-linux-dev
:EXPORT_DATE: 2020-06-16
:END:

This book had been on my TO-READ list for a long time. It came up again while I was perusing [[https://danluu.com/programming-books/][Dan Luu's Programming book list]]. I've always wanted to look behind the curtains and see how the magic worked, so I finally bought it.

I used [[https://elixir.bootlin.com/linux/v5.7.2/C/ident/task_struct][bootlin]] to read through Linux 5.7.2 source. They provide a really good search system and linked definitions. The book describes kernel version 2.6. You might want to keep this site open to see how things have changed since then.

** Process & Threads
A process begins it life with ~fork()~

Lifecycle: ~fork()~ [Create a copy of the current running process] -> ~exec()~ [Load a binary into memory] -> ~exit()~

Metadata about each process is stored in a ~task_struct~. Info about all processes are maintained in a linked-list called the tasklist. They're often referred to as process descriptors.

~thread_info~ struct is present at the bottom of the stack (for stacks that grow down). This allows for a lot of neat optimizations whereby the ~thread_info~ of the current process can be computed and found pretty quickly(review).

~fork()~ is implemented through Copy-On-Write (COW) pages. Resources are duplicated only when they are modified. The gain comes through not duplicating the address space!

Threads in linux are no different from processes. Each thread has it's own ~task_struct~ and is scheduled like any other task. Certain params in the ~task_struct~ have common values to indicate that resources are shared. This is different from Windows where threads are seen as lightweight processes, where the kernel has explicit support for dealing with threads.

Kernel threads are a special class of threads that run only in kernel space. Forked from ~kthreadd~ for performing special ops like flush, ksoftirqd.

** Scheduling
O(1) scheduler, followed by the Completely Fair Scheduler

Sticking to conventional ideas of an absolute time slice ensures constant switching rate but variable fairness and can lead to a slew of problems. CFS does away with this by ditching timeslices and allocating a portion of the processor to each process. This results in variable switching rate but constant fairness.

CFS works by assuming that there is an ideal processor that is capable of multitasking. If we have n processes, each would run in parallel, consuming 1/n of the processor. Reality deviates from this ideal dream in the fact that perfect multitasking is not possible, and that there is an overhead involved in switching processes. Nevertheless, CFS is designed with the idea of giving a portion of the processor to each running process. This portion assigned is a function of the total number of processes waiting to be run. Nice values are used here to weight the processor portion that each process receives - a lower niceness value would result in a relatively higher portion of the processor. Thus when we take an infinitely small time window, each process would've been scheduled for a time slice proportional to their processor portion.

This infinitely small window is usually approximated to a duration called ~targeted latency~. Smaller value results in higher interactivity since it approximates the ideal case, but it results in lower throughput because of switching overhead. ~targeted latency~ is floored at a value called ~minimum granularity~ by the kernel.

All the scheduling info is carried in ~sched_entity~ which is embedded in each ~task_struct~.

The most interesting thing here is the ~vruntime~, the virtual run time, which is what the scheduler uses to pick the next process. There is a concept of physical time and virtual time. Physical run time is the actual time that the process ran and virtual run time is normalized physical time computed using the number of runnable processes and the niceness value of the process. Approximately, it is computed as ~physcial_time * (NICE_0_LOAD / proc_load)~ where ~NICE_0_LOAD~ represents the weight of a process who's niceness value is 0 and ~proc_load~ represents the weight of the process calculated using its niceness value. Thus for processes with lower niceness value (higher priority), the virtual time would be less than physical time and vice versa. Thus they'd get a bigger portion of the processor in turn. This [SO](https://stackoverflow.com/questions/19181834/what-is-the-concept-of-vruntime-in-cfs/19193619) answer goes into some more depth.

CFS maintains runnable procs in a red-black tree where the key is the ~vruntime~. It continuously picks and schedules the process with the lowest ~vruntime~. It does a neat optimization where it caches the left-most node during insertion / deletion of each new node.

When a task goes to sleep, it marks itself as sleeping, puts itself on a wait Q, removes itself from the red-black tree of runnables and calls ~schedule()~ to select the new process to execute. To wake up the task, it is marked as runnable, removed from the wait Q, and put back in the runnable tree.

** System Calls
System calls provide an interface between the applications in user space and the kernel. They provide a mechanism through which applications can safely interact with the underlying hardware, create new processes, communicate with each other, as well as the capability to request other operating system resources. Provide mechanism, not policy. The kernel system calls provide a specific fn. The manner in which it is used does not matter to the kernel.

User space applications cannot directly invoke a kernel function. The whole communications happens through register values and interrupts. Each syscall has a particular value associated with it. This value is loaded into the ~eax~ register and then an interrupt is invoked ~int 0x80~ which invokes the interrupt handler which hands over control to the kernel, which then executes the appropriate system call on behalf of the user space application.

Most of the system calls are defined with the funky ~SYSCALL_DEFINE~ macro. This [answer](https://www.quora.com/Linux-Kernel/Linux-Kernel-What-does-asmlinkage-mean-in-the-definition-of-system-calls) explains the curious ~asmlinkage~ that gets prefixed to these functions. Syscall ~bar~ is referred to as ~syscall_bar~ within the kernel.

** Kernel Data Structures
The ubiquitous linked list implementation is a circular doubly linked list... with some quirks. Unlike usual linked lists, the data is not embedded within the linked list struct but rather the linked list struct ~struct list_head~ is embedded within the data struct. The kernel uses some C macro magic with ~container_of~ to get a pointer to the embedding struct from the ~list_head~ pointer. This [post](https://radek.io/2012/11/10/magical-container_of-macro/) demystifies the magic behind the macro.

In addition the kernel code also contains implementations for a queue (with the usual ops) and a map. The map is implemented as a balanced binary search tree with a rather confusing name - idr. It provides mapping between UIDs to pointers.

** Interrupts & Interrupt Handlers
Interrupts generated by H/W are handled by specific Interrupt Handlers or Interrupt Service Routines (ISR). Generally the ISR for a device is part of the device driver code in the kernel. ISR in the kernel are nothing but C functions that run in the interrupt context (atomic context). The work associated with handling an interrupt is divided into two parts -

1. Acknowledging the H/W and performing operations that will enable the H/W will proceed further (stuff like copying all the received packets from a NIC's buffer) - This is handled by the 'Top Half'.
2. Further work on the data associated with the kernel, which is not critical and can be performed at a future point in time - This is handled by the 'Bottom Half'.

An interrupt handler is registered for an IRQ line using ~request_irq()~ which takes in information about the IRQ number, handler fn, flags pertaining to the nature of the interrupt and handler, and some extra stuff. The registration happens when the driver is loaded. Similarly, when the driver is unloaded the handler needs to be freed using ~free_irq()~.

Interrupt handlers in linux need to be reentrant i.e the handler will not be invoked concurrently. When an interrupt is being service, the interrupt line is disabled (masked) which prevents further interrupts from coming on that line. Thus it is guaranteed that the ISR won't be invoked in parallel.

Interrupt lines may be shared among multiple handlers. For a line to be shared, each handler on that line must be registered as a shared handler. The handler returns a value denoting whether the interrupt was handled or not. When an interrupt is received on a shared line, the kernel invokes each of the handlers one by one. It uses the return value to ascertain whether the interrupt was handled.

Interrupt handlers run in the interrupt context. Since it is not backed by a process, ISR are not allowed to sleep (who will wake it up and how?), which restricts the activities that can be done from ISR. Earlier ISR was forced to use the stack of the process it interrupted. Now, there is an interrupt stack associated with the kernel which is of size equivalent to one page which the ISR can use.

~cat /proc/interrupts~ shows the interrupt line, the number of interrupts received by each CPU, the interrupt controller, the interrupt type, and the device.

Bottom halves may be implemented using softirqs, tasklets, or work queues.

** Synchronization

Locks are implemented using atomic test and set insturctions that are provided by the underlying architecture. Atomic operations using ~atomic_t~. There's a lot to talk about here. In the book, which is based on linux kernel 2.6, ~atomic_t~ is implemented as a ~volatile int~ inside a struct. The struct was chosen so that there would be no way to cast it into another valid form. The choice of ~volatile~ does not seem to have survived the test of time, with more recent variants moving away from it altogether. This [[https://www.kernel.org/doc/html/latest/core-api/atomic_ops.html][document]] goes through the structure and behavior of the latest version of ~atomic_t~, in addition, it also sheds light on [[https://www.kernel.org/doc/html/latest/process/volatile-considered-harmful.html#volatile-considered-harmful][why volatile should not be used]]. Most of these arise because of the reliance on ~volatile~ to enforce a memory barrier while it actually does not. This [[https://stackoverflow.com/questions/246127/why-is-volatile-needed-in-c][SO answer]] illustrates cases where volatile can be justifiably used to prevent the compiler from optimising away checks and conditions that rely on MMIO.

~atomic_t~ provides atomic operations to manipulate integers and bits. This is useful in cases where the critical region does not perform any operation more complicated than that. Locks are used when the critical regions are more complex, where multiple operations need to be performed while still ensuring atomicity.

Spin lock are a form of locking provided by the kernel, where the thread busy waits (spins) until the lock is acquired. This might seem inefficient in comparison to scenarios where the threads are put to sleep if the lock is not available. In cases where the locks are held for a short duration of time (or in code paths where you cannot sleep), spinlocks are efficient as it foregoes the overhead of scheduling involved with sleeping the thread and waking it up. An interesting fact is that the locks compile away in uniprocessor machines to markers that disable and enable kernel pre-emption. Interrupt handlers can use spin-locks, provided local interrupts to the current processor are disabled (this ensures that we do not get stuck with a double acquire deadlock). Lock data not code. Reader/writer variant of the spin lock is also provided by the kernel. A RW spin lock always favors readers. A sufficient number of readers could cause the starvation of the writer!

Semaphores in linux are sleeping locks. Can only be used in process context since it is not possible to sleep in an interrupt context (as they won't be rescheduled). Variants : binary semaphores (mutex) and counting semaphores. In addition, there's a rwsemaphore and a mutex(as a separate struct with a simpler interface).

There's another curious thing called the ~completion variable~ provided by the kernel. This is useful is scenarios where one process is waiting for a singal from the other indicating completion. A semaphore can be used here, but ~completion variable~ provides a simpler interface.

In addition to all of this there's the Big Kernel Lock (BKL) that was added to ease the SMP transition. It's a recursive, global spin lock that can be used in the process context. It's interesting to note how different projects got started with coarse grained locking, and later moved to fine grained locking as the project matured and the need for concurrency grew. I wonder when Python will tide over the Global Interpreter Lock(GIL).

Just when you thought you couldn't need another locking mechanism, the kernel throws ~seqlocks~ in your face. This is sort of like the RW locks seen earlier, with the difference being that writers are preferred over readers. Each locked data is associated with a sequence counter (which is the thing that's protected by the lock). During a write, the counter is incremented. A read operation checks the sequence counter prior to and after the read. A read succeeds(as in, a write did not happen in between), if the values match. Thus, writers are never blocked, and dirty reads would just cause the reader to retry the read until the counter conditions are satisfied.

** Ordering & Barriers
The processor and compiler might reorder memory accesses (reads and write) in code for a variety of reasons which might break some implicit assumptions that the code relies on. Barriers can be used to enforce the ordering and to indicate to the compiler / processor to maintain the order of operations. ~mb()/rmb()/wmb()~ provide memory barrier / read memory barrier / write memory barrier which ensure that rw / reads / writes are not reordered across them i.e all corresponding ops before the barrier are guaranteed to complete before the ops after it.

** Memory Management
Pages are treated as the smallest unit of memory management. Memory is divided in multiple zone, each zone with a particular characteristic (DMA, normal, high memory etc). Allocations will never cross zone boundaries. Pages returned to user-space are zeroed out to ensure security. ~kmalloc~ allocates memory that is physically contiguous while ~vmalloc~ allocates memory that is contiguous in the virtual address space.

** File Managements
VFS abstraction layers allows userland programs to be agnostic of the underlying fs. Main components: superblock, inode, dentry, file.

** Block Devices
Sectors, blocks, buffers, and buffer heads. The IO scheduler mergers and sorts requests on the block device to maximize "global" throughput. Anticipatory, deadline, completely fair queuing, and noop variant.

** TODO
*** Interesting but not interesting enough for now
- Interrupt Handler Bottoms - softirq, tasklets
- Slab allocator
* A Tale Of Two DBs
:PROPERTIES:
:EXPORT_FILE_NAME: 05-tale-of-two-dbs
:EXPORT_DATE: 2020-07-23
:END:

** Background
Work always manages to throw interesting problems my way and this one was particularly interesting. Our telephone server infrastructure and the associated cloud services were spread across two AWS regions - Singapore & Mumbai. This was primarily done to comply with Indian Data Protection Laws which mandated that customer data associated with some critical areas of business must stay within the country. We had run these two regions as independent entities, with code changes being deployed uniformly across them.

Owing to some changes we had done as part of another unification project, we managed to make the physical servers agnostic of the AWS region. It allowed us to move away from statically assigning servers to a region, and to shift capacity between regions based on demand. As a byproduct of this unification project, we had to reconcile and merge the telephone server data that was currently spread across two databases which were hosted in these two regions.

** The Problem
We had two MySQL databases housing telephone server related information in each of our two regions. The goal was to unify the view of data so that it would be the same everywhere. Essentially, the result of running a query on this data should yield the same result regardless of the region it was executed in. We had about 9 tables whose data had to be merged.

There were two impediments that faced us:
- **Primary Key(PK) conflicts**: PKs were reused across regions, since they were agnostic of each other, which would cause problems if we went for a blind merge.
- **Foreign Key(FK) dependency**: This is primarily a side effect on the above. Any change in PKs should take the FK relationships into account so that data consistency is maintained at the end of the operation.

** The Solution

Our databases were slightly asymmetrical such that one region had significantly more data than the other. Adding an offset to the PKs in the smaller DB would ensure that the PKs are continuous and conflict free between the regions. Once the PKs were fixed, we could take a dump and merge the data.

![DB](/db.png)

To keep the foreign key relationships intact, the changes would have to be propagated to all the tables that referenced these PK columns. The reference relationship can be obtained using the [INFORMATION_SCHEMA.KEY_COLUMN_USAGE](https://dev.mysql.com/doc/refman/8.0/en/information-schema-key-column-usage-table.html) table. A simple query like the one detailed in [this SO answer](https://stackoverflow.com/questions/806989/how-to-find-all-tables-that-have-foreign-keys-that-reference-particular-table-co) would get us all the tables referring to a particular column of a chosen table. When you're working with multiple tables with multiple relationships, it's always best to visualize this information to make tracking a little easier. The edges on the graph below denote the column of the referring table which refers to the PK of the referred table.

![FK](/fk.png)

We prepared the list of queries and scripts to be executed beforehand to minimize downtime and to prevent manual errors. MySQL supports [Prepared Statements](https://dev.mysql.com/doc/refman/8.0/en/sql-prepared-statements.html) which is sort of like a DSL that allows us to create (or "prepare") SQL statements and then execute them. It has basic support for variables, which allows us to write generic SQL queries that can be applied to a lot of tables through the use of variables. This enabled us to cut the canned query size to a large extent.

** The Execution

Because of the nature of our system, we could never completely freeze access to the DBs. So we started with the activity during a lean period, when traffic was negligible to minimize outward impacts.

We started by taking a backup of the DBs in both the regions, just to be extra safe. There are a few system level variables that MySQL maintains which dictates the behaviour of the database engine. One of them is [foreign_key_checks](https://dev.mysql.com/doc/refman/5.6/en/server-system-variables.html#sysvar_foreign_key_checks) which indicates whether foreign key constraints would be respected or not. This constraint flag was disabled during the migration, since there was no way to alter the PK without violating the FK relationships. The canned statements were then executed on the smaller DB to fix the PKs and FKs. Once the PK changes were back-propagated, foreign_key_checks were enabled again. Once the changes were made and canned queries were executed in the smaller DB, it was merely a matter of taking a `mysqldump` from each region and applying it in the other region.

** Lessons Learned

-   ALWAYS take backups. The more the better. I've seen multiple downtimes but messing with production databases and unifying data at this scale remains the single most scariest thing I've done to pubDate. So, it's always good to err on the side of caution, even if it's a slower and longer path.
-   Freeze access to your DBs during data migration: We found that one of the update queries from an automated script had gotten through during the migration phase which resulted in the FK relations getting screwed up. Thankfully, MySQL prevents any updates to a tables once it detects a violation of FK constraints. This allowed us to zero in on the problem and fix it.
-   Use prepared statements and canned SQL statements for execution to minimize human error.

Supposedly, the whole process would've been a lot easier if we used UUIDs instead of auto incremented ints for our PKs. There's a wealth of opinions on the web arguing [for](https://medium.com/@Mareks_082/auto-increment-keys-vs-uuid-a74d81f7476a) and [against](https://www.percona.com/blog/2019/11/22/uuids-are-popular-but-bad-for-performance-lets-discuss/) this approach.

Ping me your thoughts and comments.
